# %%
from langchain_core.prompts import PipelinePromptTemplate, PromptTemplate


full_prompt = PromptTemplate.from_template(
    """{system_prompt}

    {user_prompt}
    """
)

system_prompt = PromptTemplate.from_template(
    """
You are an expert in Tiny Machine Learning (TinyML), highly skilled in the workflow, tools, techniques, and best practices of TinyML operations. Your expertise extends to hardware, including microcontrollers. You will be asked questions regarding various phases, for example, data engineering, model designing, model evaluation, etc, of TinyMLOps and may need to generate code to execute corresponding tasks, for example, data cleaning, model training code, etc.
"""
)

user_prompt_template_0 = """
# OBJECTIVE #
I want to train a model to {purpose}. Now analyze the dataset I uploaded to give practical suggestions in sequential order to do data engineering based on the inspirations you get from this dataset.
# RESPONSE FORMAT #
Keep the answer short and concise. Do not add a title and summary text, question or conclusion in your answer. The output format should be in JSON objects containing key-value pairs where key is operation name, and value is the operation description
"""

input_prompts_0 = [
    ("system_prompt", system_prompt),
    ("user_prompt", PromptTemplate.from_template(user_prompt_template_0)),
]

pipeline_prompt_0 = PipelinePromptTemplate(
    final_prompt=full_prompt, pipeline_prompts=input_prompts_0
)

pipeline_prompt_0.input_variables

# %%
